import 'dart:typed_data';
import 'package:flutter/material.dart';
import 'package:camera/camera.dart';
import 'package:tflite_flutter/tflite_flutter.dart';
import 'package:tflite_flutter_helper/tflite_flutter_helper.dart';

class CameraPage extends StatefulWidget {
  final String? course;
  const CameraPage({super.key, this.course});

  @override
  State<CameraPage> createState() => _CameraPageState();
}

class _CameraPageState extends State<CameraPage> {
  CameraController? _controller;
  late Interpreter _interpreter;

  String? _selectedCourse;
  bool _isDetecting = false;

  @override
  void initState() {
    super.initState();
    _selectedCourse = widget.course; // ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡∏Ñ‡πà‡∏≤‡πÉ‡∏ô constructor ‡∏Å‡πá‡πÄ‡∏Å‡πá‡∏ö‡πÑ‡∏ß‡πâ‡∏Å‡πà‡∏≠‡∏ô
    _initializeCamera();
    _loadModel();
  }

  @override
  void didChangeDependencies() {
    super.didChangeDependencies();
    // ‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ñ‡∏≠‡∏£‡πå‡∏™‡∏à‡∏≤‡∏Å constructor ‡∏•‡∏≠‡∏á‡∏î‡∏∂‡∏á‡∏à‡∏≤‡∏Å route arguments
    if (_selectedCourse == null) {
      final args = ModalRoute.of(context)?.settings.arguments;
      if (args != null && args is String) {
        setState(() {
          _selectedCourse = args;
        });
        print("üßò Course selected via route args: $_selectedCourse");
      }
    }
  }

  Future<void> _initializeCamera() async {
    final cameras = await availableCameras();
    final frontCam = cameras.firstWhere(
      (cam) => cam.lensDirection == CameraLensDirection.front,
    );

    _controller = CameraController(frontCam, ResolutionPreset.medium);

    await _controller!.initialize();

    // ‡πÄ‡∏£‡∏¥‡πà‡∏° stream ‡∏†‡∏≤‡∏û‡∏à‡∏≤‡∏Å‡∏Å‡∏•‡πâ‡∏≠‡∏á
    await _controller!.startImageStream(_processCameraImage);

    if (!mounted) return;
    setState(() {});
  }

  Future<void> _loadModel() async {
    _interpreter = await Interpreter.fromAsset('models/move.tflite');
    print('‚úÖ Model loaded!');
  }

  void _processCameraImage(CameraImage image) async {
    if (_isDetecting) return;
    _isDetecting = true;

    try {
      final inputTensor = _interpreter.getInputTensor(0);
      final inputShape = inputTensor.shape; // [1, height, width, 3]
      final inputHeight = inputShape[1];
      final inputWidth = inputShape[2];

      // ‡πÅ‡∏õ‡∏•‡∏á‡∏†‡∏≤‡∏û YUV420 => RGB
      final rgbBytes = _convertYUV420ToImage(image);

      // ‡∏™‡∏£‡πâ‡∏≤‡∏á TensorImage ‡∏à‡∏≤‡∏Å bytes
      TensorImage inputImage = TensorImage.fromBytes(
        bytes: rgbBytes,
        shape: [image.height, image.width, 3],
      );

      // ‡∏™‡∏£‡πâ‡∏≤‡∏á ImageProcessor ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö resize ‡πÉ‡∏´‡πâ‡∏û‡∏≠‡∏î‡∏µ‡∏Å‡∏±‡∏ö model input
      ImageProcessor imageProcessor = ImageProcessorBuilder()
          .add(ResizeOp(inputHeight, inputWidth, ResizeMethod.BILINEAR))
          .build();

      inputImage = imageProcessor.process(inputImage);

      // ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏° output buffer
      final output = List.generate(1, (_) => List.filled(17 * 3, 0.0));

      // ‡∏£‡∏±‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•
      _interpreter.run(inputImage.buffer, output);

      // debug: print keypoints ‡∏ö‡∏≤‡∏á‡∏™‡πà‡∏ß‡∏ô
      print('üßç‚Äç‚ôÇÔ∏è Output keypoints sample: ${output[0].sublist(0, 6)}');

      // TODO: ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏• keypoints ‡∏ö‡∏ô UI ‡∏ï‡πà‡∏≠‡πÑ‡∏î‡πâ

    } catch (e) {
      print("Error processing image: $e");
    }

    _isDetecting = false;
  }

  Uint8List _convertYUV420ToImage(CameraImage image) {
    final width = image.width;
    final height = image.height;
    final uvRowStride = image.planes[1].bytesPerRow;
    final uvPixelStride = image.planes[1].bytesPerPixel!;

    final img = Uint8List(width * height * 3);

    for (int y = 0; y < height; y++) {
      for (int x = 0; x < width; x++) {
        final uvIndex =
            uvPixelStride * (x ~/ 2) + uvRowStride * (y ~/ 2);

        final yp = image.planes[0].bytes[y * width + x];
        final up = image.planes[1].bytes[uvIndex];
        final vp = image.planes[2].bytes[uvIndex];

        int r = (yp + (1.370705 * (vp - 128))).clamp(0, 255).toInt();
        int g = (yp - (0.337633 * (up - 128)) - (0.698001 * (vp - 128)))
            .clamp(0, 255)
            .toInt();
        int b = (yp + (1.732446 * (up - 128))).clamp(0, 255).toInt();

        final pixelIndex = y * width * 3 + x * 3;
        img[pixelIndex] = r;
        img[pixelIndex + 1] = g;
        img[pixelIndex + 2] = b;
      }
    }
    return img;
  }

  @override
  void dispose() {
    _controller?.dispose();
    _interpreter.close();
    super.dispose();
  }

  @override
  Widget build(BuildContext context) {
    if (_controller == null || !_controller!.value.isInitialized) {
      return const Scaffold(
        body: Center(child: CircularProgressIndicator()),
      );
    }

    return Scaffold(
      appBar: AppBar(
        title: Text('‡∏ù‡∏∂‡∏Å: ${_selectedCourse ?? "‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏"}'),
      ),
      body: Stack(
        children: [
          CameraPreview(_controller!),
          Positioned(
            bottom: 20,
            left: 20,
            child: Container(
              padding: const EdgeInsets.all(8),
              color: Colors.black54,
              child: Text(
                'Course: ${_selectedCourse ?? "None"}',
                style: const TextStyle(color: Colors.white, fontSize: 18),
              ),
            ),
          )
          // TODO: ‡∏ß‡∏≤‡∏î‡∏à‡∏∏‡∏î keypoints ‡∏ó‡∏±‡∏ö‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà‡πÑ‡∏î‡πâ
        ],
      ),
    );
  }
}
